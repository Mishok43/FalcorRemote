{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if False:\n",
    "    # Set environment variables\n",
    "    falcor_dir = \"D://NeuralFalcor//neuralrender2//build//windows-vs2022//bin//Release//\"  # Replace with the correct path\n",
    "    os.environ[\"FALCOR_DIR\"] = falcor_dir\n",
    "    os.environ[\"PATH\"] = f\"{falcor_dir};{os.environ['PATH']}\"\n",
    "    os.environ[\"PYTHONPATH\"] = f\"{falcor_dir}python;{os.environ.get('PYTHONPATH', '')}\"\n",
    "\n",
    "    # Confirm the environment variables are set\n",
    "    print(\"FALCOR_DIR:\", os.environ[\"FALCOR_DIR\"])\n",
    "    print(\"PATH:\", os.environ[\"PATH\"])\n",
    "    print(\"PYTHONPATH:\", os.environ[\"PYTHONPATH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda\\envs\\falcor-pytorch\\lib\\site-packages\\tinycudann\\modules.py:53: UserWarning: tinycudann was built for lower compute capability (86) than the system's (89). Performance may be suboptimal.\n",
      "  warnings.warn(f\"tinycudann was built for lower compute capability ({cc}) than the system's ({system_compute_capability}). Performance may be suboptimal.\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import falcor\n",
    "import time\n",
    "import numpy as np\n",
    "import pyexr as exr\n",
    "import sys\n",
    "import os\n",
    "import dataclasses\n",
    "import datetime\n",
    "import glob\n",
    "import argparse\n",
    "\n",
    "sys.path.append(os.path.join(os.path.abspath(''), \"..\"))\n",
    "import common\n",
    "import material_utils\n",
    "from loss import compute_render_loss_L1, compute_render_loss_L2\n",
    "\n",
    "\n",
    "import common\n",
    "import os\n",
    "from falcor import Camera, float3, uint2\n",
    "import copy\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "try:\n",
    "\timport tinycudann as tcnn\n",
    "except ImportError:\n",
    "\tprint(\"This sample requires the tiny-cuda-nn extension for PyTorch.\")\n",
    "\tprint(\"You can install it by running:\")\n",
    "\tprint(\"============================================================\")\n",
    "\tprint(\"tiny-cuda-nn$ cd bindings/torch\")\n",
    "\tprint(\"tiny-cuda-nn/bindings/torch$ python setup.py install\")\n",
    "\tprint(\"============================================================\")\n",
    "\tsys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:/Models/\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "class ExperimentParams:\n",
    "    def __init__(self):\n",
    "        # Load the configuration from YAML file\n",
    "        with open('config.yaml', 'r') as file:\n",
    "            config = yaml.safe_load(file)['ExperimentParams']\n",
    "\n",
    "        self.MODELS_PATH = config.get('MODELS_PATH')\n",
    "\n",
    "params = ExperimentParams()\n",
    "print(params.MODELS_PATH)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def float3tonumpy(v):\n",
    "    return np.array([v.x, v.y, v.z])\n",
    "\n",
    "def numpytofloat3(n):\n",
    "    return float3(*np.copy(n))\n",
    "\n",
    "def numpytouint2(n):\n",
    "    return uint2(*np.copy(n))\n",
    "\n",
    "\n",
    "class ExperimentParams:\n",
    "    #render_width = 256 # random\n",
    "    #render_height = 256\n",
    "    render_width = 1280 # random\n",
    "    render_height = 720\n",
    "\n",
    "    enable_MIS = False \n",
    "    enable_sky_learning = True # for example we could disable it and compare NIRC with NRC\n",
    "\n",
    "    relative_error = False\n",
    "\n",
    "    USE_GBUFFER = True\n",
    "    relative_error_eps = 0.001\n",
    "    \n",
    "\n",
    "    RECOMPUTE_LOSS = {\"NIRC\": False, \"NIRC_EM\": False, \"SH\": False, \"VMF\": False, \"NCV\": False}\n",
    "\n",
    "    GRADIENT_CLIP = 0.001\n",
    "    SKIP_TENSOR_CHECK = True # disable if you have problems with NaNs, Inf or just 0 loss\n",
    "    ADAM_BETAS = [0.98, 0.9999]\n",
    "    ADAM_LR = 0.01\n",
    "    num_training_frames = 150 # we gotta use the same number of training frames for all models to make conduct fair experiments!. USE a BIIG number for the final experiments (4k? 5k?)\n",
    "\n",
    "    # MODELS_PATH = \"E:/Models/\" # we can just put it in the same folder as the script?\n",
    "    MODELS_PATH = params.MODELS_PATH\n",
    "\n",
    "    is_training = False\n",
    "\n",
    "\n",
    "\n",
    "gparams = ExperimentParams()\n",
    "\n",
    "\n",
    "\n",
    "class ValidationPoint:\n",
    "    xn: float\n",
    "    yn: float\n",
    "\n",
    "    x: int\n",
    "    y: int\n",
    "\n",
    "    id: int\n",
    "    \n",
    "    position: np.ndarray\n",
    "    target: np.ndarray\n",
    "    normal: np.ndarray\n",
    "\n",
    "    is_init: bool\n",
    "\n",
    "    def __init__(self, xn: float, yn: float):\n",
    "        self.xn = xn\n",
    "        self.yn = yn\n",
    "\n",
    "        self.x = int(gparams.render_width*xn)\n",
    "        self.y = int(gparams.render_height*yn)\n",
    "\n",
    "        self.id = self.y*gparams.render_width+self.x\n",
    "\n",
    "        self.is_init = False\n",
    "\n",
    "\n",
    "    def init_surface_data(self, p: np.ndarray, t: np.ndarray, n: np.ndarray):\n",
    "        self.is_init = True\n",
    "\n",
    "        self.position = p\n",
    "        self.target = t\n",
    "        self.n = n\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SceneConfig:\n",
    "    model_path: str\n",
    "    camera_position: np.ndarray\n",
    "    camera_target: np.ndarray\n",
    "    tonemapper_exposure: float\n",
    "    focal_length: float\n",
    "    \n",
    "    validation_points: List[ValidationPoint]\n",
    "    emissive_factor: float = 1.0\n",
    "    \n",
    "\n",
    "    def __init__(self, model_path: str, camera_position: Tuple[float, float, float], camera_target: Tuple[float, float, float], tonemapper_exposure: float = 0, focal_length: float = None, selected_points: List[Tuple[float, float]] = [], \n",
    "                 up: Tuple[float, float, float] = [0.0, 1.0, 0.0], lr_factor: float = 1.0, epochs: int = 4000, roughness: float = 1.0, var_est_steps: int = 1000):\n",
    "        self.model_path = gparams.MODELS_PATH + model_path\n",
    "        self.model_name = os.path.dirname(model_path)\n",
    "        self.camera_position = np.array(camera_position)\n",
    "        self.camera_target = np.array(camera_target)\n",
    "        self.epochs = epochs\n",
    "        self.var_est_steps = var_est_steps\n",
    "        self.tonemapper_exposure = tonemapper_exposure\n",
    "        self.roughness = roughness\n",
    "        self.lr_factor = lr_factor\n",
    "        self.checkpoint_dir = os.path.join('checkpoints', self.model_name)\n",
    "        os.makedirs(self.checkpoint_dir, exist_ok=True)\n",
    "\n",
    "        \n",
    "        self.focal_length = focal_length\n",
    "        self.validation_points = []\n",
    "        self.up = up\n",
    "\n",
    "        for p in selected_points:\n",
    "            self.validation_points.append(ValidationPoint(xn=p[0], yn=p[1]))\n",
    "\n",
    "    def camera_position_f3(self) -> float3:\n",
    "        return numpytofloat3(self.camera_position)\n",
    "\n",
    "    def camera_target_f3(self) -> float3:\n",
    "        return numpytofloat3(self.camera_target)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"SceneConfig(model_path={self.model_path}, camera_position={self.camera_position.tolist()}, camera_target={self.camera_target.tolist()}, tonemapper_exposure={self.tonemapper_exposure}, focal_length={self.focal_length})\"\n",
    "\n",
    "    def add_validation_point(self, p: Tuple[float, float]):\n",
    "        self.validation_points.append(ValidationPoint(xn=p[0], yn=p[1]))\n",
    "\n",
    "    def setup_validation_points(self, mlData):\n",
    "        positions = mlData[\"worldpos\"] \n",
    "        normals = mlData[\"normal\"]\n",
    "\n",
    "        for i in range(len(self.validation_points)):\n",
    "            p = self.validation_points[i]\n",
    "            pos = positions[p.id].cpu().numpy() # we should get it from the gpu torch in some way \n",
    "            normal = normals[p.id].cpu().numpy()\n",
    "\n",
    "            p.init_surface_data(p = pos+normal*0.00001, t = pos+normal+normal*0.00001, n = normal)\n",
    "            \n",
    "    def prepare_scene(self, scene, debugPointID=None):\n",
    "        scene.roughnessMultiplier = self.roughness\n",
    "\n",
    "        if debugPointID == None:\n",
    "            scene.camera.position = numpytofloat3(self.camera_position)\n",
    "            scene.camera.target = numpytofloat3(self.camera_target)\n",
    "            if self.focal_length != None:\n",
    "                scene.camera.focalLength = self.focal_length\n",
    "            scene.camera.useHemisphericalCamera = False\n",
    "            scene.camera.up = numpytofloat3(self.up)\n",
    "        else:\n",
    "            vp = self.validation_points[debugPointID]\n",
    "            scene.camera.useHemisphericalCamera = True\n",
    "            scene.camera.position = numpytofloat3(vp.position)\n",
    "            scene.camera.target = numpytofloat3(vp.target)\n",
    "            scene.camera.up = numpytofloat3(self.up)\n",
    "            assert(vp.is_init)\n",
    "\n",
    "# some specular scenes? we could just import the specular sponza\n",
    "scenes = {\n",
    "    \"CornellBox\": SceneConfig(\"CornellBox/cornell_box.pyscene\", camera_position=[0, 0.28, 0.6], camera_target=[0, 0.28, 0], selected_points=[[0.35, 0.5], [0.65, 0.4]], epochs=2000),\n",
    "    \"CornellBoxEnv\": SceneConfig(\"CornellBoxEnv/cornell_box_env.pyscene\", camera_position=[0, 0.28, 0.6], camera_target=[0, 0.28, 0], selected_points=[[0.35, 0.5], [25.0/256.0, 150.0/256.0]]),\n",
    "    \"EnvDebug\": SceneConfig(\"EnvDebug/env_debug.pyscene\", camera_position=[0, 0.28, 0.6], camera_target=[0, 0.28, 0], selected_points=[[0.35, 0.5], [0.65, 0.4]]),\n",
    "    #\"CornellBox\": SceneConfig(\"CornellBox/cornell_box.pyscene\", camera_position=[0, 0.28, 1.2], camera_target=[0, 0.28, 0], selected_points=[[0.35, 0.5], [0.65, 0.4]]),\n",
    "    \"Bistro\" : SceneConfig(\"Bistro/BistroExterior.pyscene\", camera_position=[-29.195, 5.145, -8.768], camera_target=[-28.212, 5.137, -8.586], selected_points=[[400.0/1280, 400.0/720], [410/1200.0, 200.0/720], [800/1280.0, 600/720.0]]),\n",
    "    \"CountryKitchen\": SceneConfig(\"CountryKitchen/Country-Kitchen.gltf\", camera_position=[1.456, 1.509, 1.602], camera_target=[0.678, 1.471, 0.974], selected_points=[[0.35, 0.5], [0.65, 0.4]], lr_factor=0.5, epochs=2000, var_est_steps=3000),\n",
    "    \"SanMiguel\": SceneConfig(\"SanMiguel/san-miguel.pyscene\", camera_position=[22.2190, 3.3300, 6.7120], camera_target=[21.5799, 3.3054, 5.9432], selected_points=[[0.35, 0.5], [0.65, 0.4]], focal_length=17.750),\n",
    "    \"TheWhiteRoomCycles\": SceneConfig(\"TheWhiteRoomCycles/the-white-room_0001.gltf\", camera_position=[2.781, 1.247, 5.251], camera_target=[2.151, 1.195, 4.477], selected_points=[[0.35, 0.5], [0.65, 0.4]], lr_factor=0.25),\n",
    "    \"Sponza\": SceneConfig(\"Sponza/Sponza.pyscene\", camera_position=[8.084, 1.708, 0.827], camera_target=[7.091, 1.684, 0.715], selected_points=[[0.5, 0.1], [0.65, 0.2]], focal_length=16.750),\n",
    "    \"SponzaSpecular\": SceneConfig(\"SponzaSpecular/SponzaSpecular.pyscene\", camera_position=[-9.0311, 1.1590, -1.2149], camera_target=[-8.0785, 1.0369, -0.9365], selected_points=[[0.5, 0.8], [0.15, 0.5]], epochs=2000, roughness=0.25) \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scene Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_cfg = scenes[\"CornellBox\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUR_DIR = os.path.abspath('')\n",
    "sys.path.append(os.path.join(CUR_DIR, \"..\"))\n",
    "\n",
    "\n",
    "output_dir = CUR_DIR + \"/results/\"\n",
    "\n",
    "\n",
    "device_id = 0\n",
    "testbed = common.create_testbed([gparams.render_width, gparams.render_height])\n",
    "device = testbed.device\n",
    "\n",
    "\n",
    "# Load the reference scene.\n",
    "ref_scene = common.load_scene(\n",
    "    testbed,\n",
    "    scene_cfg.model_path,\n",
    "    gparams.render_width / gparams.render_height,\n",
    ")\n",
    "\n",
    "\n",
    "# I don't know why but useAnalyticLights and useEnvLight have False value if we start the renderer from the python side. haven't managed to found the root of this bizarre behaviour. it must be a bug -> TO DO: MAKE SURE and REPORT ABOUT IT!!\n",
    "ref_scene.renderSettings = falcor.SceneRenderSettings(useEnvLight=True, useAnalyticLights=True, useEmissiveLights=True, useGridVolumes=True)\n",
    "\n",
    "\n",
    "# init structure buffers that we need for ML side\n",
    "# color = albedo+specular reflectance\n",
    "field_types = {\"radiance\": \"float3\", \"dir\": \"float3\", \"thp\": \"float3\", \"worldpos\": \"float3\", \"normal\": \"float3\", \"color\": \"float3\", \"dradiance\": \"float3\", \"view\": \"float3\", \"roughness\": \"float\", \"pdf\": \"float\"}\n",
    "ml_data = device.create_structured_buffer(\n",
    "    struct_size = 12*8+4*2,\n",
    "    element_count=gparams.render_width*gparams.render_height,\n",
    "    bind_flags=falcor.ResourceBindFlags.ShaderResource  \n",
    "    | falcor.ResourceBindFlags.UnorderedAccess\n",
    "    | falcor.ResourceBindFlags.Shared\n",
    ")\n",
    "\n",
    "\n",
    "rays_fields = {\"worldpos\": \"float3\", \"dir\": \"float3\"}\n",
    "ml_rays_data = device.create_structured_buffer(\n",
    "    struct_size = 12*2,\n",
    "    element_count=gparams.render_width*gparams.render_height,\n",
    "    bind_flags=falcor.ResourceBindFlags.ShaderResource  \n",
    "    | falcor.ResourceBindFlags.UnorderedAccess\n",
    "    | falcor.ResourceBindFlags.Shared\n",
    ")\n",
    "\n",
    "\n",
    "device.render_context.wait_for_falcor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_graph = testbed.create_render_graph(\"StandardPathTracer\")\n",
    "\n",
    "# Create the PathTracer pass.\n",
    "path_tracer_pass = render_graph.create_pass(\n",
    "    \"PathTracer\",\n",
    "    \"PathTracer\",\n",
    "    {\n",
    "        \"samplesPerPixel\": 1, \"useSER\": False, \"useMIS\": gparams.enable_MIS, \"disableCaustics\": True\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "primary_render_pass_name = \"GBufferRT\" if gparams.USE_GBUFFER else \"VBufferRT\"\n",
    "if  gparams.USE_GBUFFER:\n",
    "    primary_render_pass = render_graph.create_pass(\n",
    "        primary_render_pass_name,\n",
    "        primary_render_pass_name,\n",
    "        {\n",
    "            \"samplePattern\": \"Center\",\n",
    "            \"sampleCount\": 1,\n",
    "            \"useAlphaTest\": True\n",
    "        }\n",
    "    )\n",
    "    render_graph.mark_output(primary_render_pass_name+\".vbuffercache\")\n",
    "    render_graph.mark_output(primary_render_pass_name+\".brdf\")\n",
    "else:\n",
    "    # Create the VBufferRT pass.\n",
    "    primary_render_pass = render_graph.create_pass(\n",
    "        primary_render_pass_name,\n",
    "        primary_render_pass_name,\n",
    "        {\n",
    "            \"samplePattern\": \"Center\",\n",
    "            \"sampleCount\": 1,\n",
    "            \"useAlphaTest\": True\n",
    "        }\n",
    "    )\n",
    "\n",
    "AccumulatePass = render_graph.createPass(\"AccumulatePass\", \"AccumulatePass\", {'enabled': True, 'precisionMode': 'Single'})\n",
    "ToneMapper = render_graph.createPass(\"ToneMapper\", \"ToneMapper\", {'autoExposure': False, 'exposureCompensation': 0.0, 'outputFormat': 'RGBA32Float' }) \n",
    "\n",
    "\n",
    "\n",
    "# Add edges to connect the passes.\n",
    "\n",
    "render_graph.add_edge(primary_render_pass_name+\".vbuffer\", \"PathTracer.vbuffer\")\n",
    "\n",
    "\n",
    "render_graph.add_edge(primary_render_pass_name+\".viewW\", \"PathTracer.viewW\")\n",
    "render_graph.add_edge(primary_render_pass_name+\".mvec\", \"PathTracer.mvec\")\n",
    "\n",
    "render_graph.addEdge(\"PathTracer.color\", \"AccumulatePass.input\")\n",
    "render_graph.addEdge(\"AccumulatePass.output\", \"ToneMapper.src\")\n",
    "\n",
    "\n",
    "# Mark the output of the PathTracer pass.\n",
    "render_graph.markOutput(\"ToneMapper.dst\")\n",
    "render_graph.mark_output(\"AccumulatePass.output\")\n",
    "render_graph.mark_output(\"PathTracer.color\")\n",
    "\n",
    "# Assign the configured render graph to the testbed.\n",
    "testbed.render_graph = render_graph\n",
    "\n",
    "path_tracer_pass.mlData = ml_data\n",
    "primary_render_pass.mlRaysData = ml_rays_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_cfg.prepare_scene(ref_scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "def adjust_gamma(image, gamma=2.2):\n",
    "\treturn (image )**(1 / gamma)\n",
    "\n",
    "\n",
    "def frameRender(num_samples=1024, vis = True, tonemapped=False,  directEmissive=True, directSky=True):\n",
    "    # may take some time to recompile the shaders becase of changed defines\n",
    "    AccumulatePass.reset()\n",
    "    AccumulatePass.enabled = True\n",
    "    primary_render_pass.sampleCount = 16\n",
    "    \n",
    "    path_tracer_pass.useMIS = True\n",
    "    path_tracer_pass.mlTraining = False\n",
    "    path_tracer_pass.directEmissive = directEmissive\n",
    "    path_tracer_pass.directSky = directSky\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        testbed.frame()\n",
    "\n",
    "    if tonemapped:\n",
    "        img = testbed.render_graph.get_output(\"ToneMapper.dst\").to_numpy()[:, :, :3]\n",
    "        img = adjust_gamma(img)\n",
    "    else:\n",
    "        img = testbed.render_graph.get_output(\"AccumulatePass.output\").to_numpy()[:, :, :3]\n",
    "    if not vis:\n",
    "        return img\n",
    "\n",
    "\n",
    "    plt.imshow(img)\n",
    "\n",
    "    path_tracer_pass.directEmissive = True\n",
    "    path_tracer_pass.directSky = True\n",
    "    path_tracer_pass.useMIS = gparams.enable_MIS \n",
    "    primary_render_pass.sampleCount = 1\n",
    "    AccumulatePass.enabled = False\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainFrame():\n",
    "    path_tracer_pass.useMIS = False\n",
    "    path_tracer_pass.indirectSky = gparams.enable_sky_learning\n",
    "    path_tracer_pass.mlTraining = True\n",
    "    testbed.frame()\n",
    "    path_tracer_pass.useMIS = True\n",
    "    path_tracer_pass.indirectSky = True\n",
    "    path_tracer_pass.mlTraining = False\n",
    "        \n",
    "def setupBRDFCache():\n",
    "    path_tracer_pass.useMIS = False\n",
    "    path_tracer_pass.indirectSky = gparams.enable_sky_learning\n",
    "    path_tracer_pass.mlTraining = True\n",
    "    primary_render_pass.cacheVisibility = True\n",
    "    primary_render_pass.brdfRender = False\n",
    "    testbed.frame()\n",
    "    primary_render_pass.brdfRender = False\n",
    "    primary_render_pass.cacheVisibility = False\n",
    "    path_tracer_pass.useMIS = True\n",
    "    path_tracer_pass.indirectSky = True\n",
    "    path_tracer_pass.mlTraining = False\n",
    "\n",
    "\n",
    "def getBRDF(pixel):\n",
    "    path_tracer_pass.useMIS = False\n",
    "    path_tracer_pass.indirectSky = gparams.enable_sky_learning\n",
    "    path_tracer_pass.mlTraining = True\n",
    "    primary_render_pass.brdfRender = True\n",
    "    primary_render_pass.targetPixel = numpytouint2(pixel)\n",
    "    testbed.frame()\n",
    "    primary_render_pass.brdfRender = False\n",
    "    path_tracer_pass.useMIS = True\n",
    "    path_tracer_pass.indirectSky = True\n",
    "    path_tracer_pass.mlTraining = False\n",
    "    brdf = testbed.render_graph.get_output(primary_render_pass_name+\".brdf\").to_numpy()[:, :, :3]\n",
    "    return brdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testbed.end_frame_forced()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to remove it\n",
    "scene_cfg.prepare_scene(ref_scene)\n",
    "\n",
    "im = frameRender(num_samples = 1, vis=True, tonemapped=True)\n",
    "# this should produce a converged render from the correct camera viewpoint (+- as in the paper teaser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def falcor_to_torch(buffer: falcor.Buffer, dtype=torch.float32):\n",
    "    params = torch.tensor([0]*(buffer.element_count*12), dtype=dtype)\n",
    "    buffer.copy_to_torch(params)\n",
    "    device.render_context.wait_for_cuda()\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_field(data, start, struct_size, field_size):\n",
    "    return torch.cat([data[i:i + field_size] for i in range(start, data.numel(), struct_size)])\n",
    "\n",
    "def falcor_to_torch_split_interleaved(buffer, field_types, dtype=torch.float32):\n",
    "    # Size mapping for different types (add more types if needed)\n",
    "    size_mapping = {\n",
    "        \"float3\": 3,  # 3 floats in a float3\n",
    "        \"float\": 1\n",
    "    }\n",
    "\n",
    "    # Calculate the size of one complete set of fields\n",
    "    struct_size = sum(size_mapping[field_type] for field_type in field_types.values())\n",
    "    # Calculate the total size of the tensor\n",
    "    total_size = struct_size * buffer.element_count    \n",
    "    all_data = buffer.to_torch([total_size])\n",
    "    device.render_context.wait_for_cuda()\n",
    "\n",
    "    # Splitting the tensor into separate tensors for each field considering interleaved structure\n",
    "    tensors = {}\n",
    "    offset = 0\n",
    "    for i, (field_name, field_type) in enumerate(field_types.items()):\n",
    "        field_size  = size_mapping[field_type]\n",
    "\n",
    "        # Reshaping data\n",
    "        reshaped_data = all_data.view(-1, struct_size)\n",
    "        # Extracting field without using a loop\n",
    "        tensors[field_name] = reshaped_data[:, offset: offset + field_size]\n",
    "        offset += field_size\n",
    "\n",
    "    return tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlDataOutput = falcor_to_torch_split_interleaved(ml_data, field_types)\n",
    "mlDataRaysOutput = falcor_to_torch_split_interleaved(ml_rays_data, rays_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlDataOutput_ref = {k: v.clone() for k, v in mlDataOutput.items()}\n",
    "mlDataRaysOutput_ref = {k: v.clone() for k, v in mlDataRaysOutput.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we gotta inform the validation points about the corresponding surface parameters (where we're gonna capute the hemispherical incident light visualization) \n",
    "#scene_cfg.add_validation_point([900/1280.0, 100/720.0])\n",
    "scene_cfg.setup_validation_points(mlDataOutput_ref)\n",
    "scene_cfg.prepare_scene(ref_scene, debugPointID=0)\n",
    "im = frameRender(num_samples = 1, vis=True, tonemapped=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_cfg.prepare_scene(ref_scene)\n",
    "\n",
    "im = frameRender(num_samples = 1, vis=True, tonemapped=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_cfg.prepare_scene(ref_scene)\n",
    "_ = frameRender(num_samples=1, tonemapped=True)\n",
    "setupBRDFCache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "falcor-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
